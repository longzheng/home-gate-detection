{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loop over images in `/sample/original` to crop them to just the gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "original_jpg_files = glob.glob('./sample/original/*.jpg')\n",
    "\n",
    "for index, file in enumerate(original_jpg_files):\n",
    "    # Process each file here\n",
    "    im = Image.open(file)\n",
    "\n",
    "    # Size of the image in pixels (size of original image)\n",
    "    # (This is not mandatory)\n",
    "    width, height = im.size\n",
    "\n",
    "    left = 2142\n",
    "    top = 333\n",
    "    right = left + 585\n",
    "    bottom = top + 468\n",
    "\n",
    "    # Cropped image of above dimension\n",
    "    im1 = im.crop((2142, 333, right, bottom))\n",
    "\n",
    "    # save the cropped image in `cropped` folder, create folder if necessary\n",
    "    im1.save(file.replace('original', 'cropped'))\n",
    "\n",
    "    print(\"processed {} of {}\".format(index + 1, len(original_jpg_files)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### send to Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from roboflow import Roboflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "# Initialize the Roboflow object with your API key\n",
    "rf = Roboflow(api_key=os.environ.get(\"ROBOFLOW_API_KEY\"))\n",
    "\n",
    "# Retrieve your current workspace and project name\n",
    "print(rf.workspace())\n",
    "\n",
    "# Specify the project for upload\n",
    "project = rf.workspace(\"long-zheng-bzpnl\").project(\"gate-open-or-closed\")\n",
    "\n",
    "cropped_jpg_files = glob.glob('./sample/cropped/*.jpg')\n",
    "\n",
    "for index, file in enumerate(cropped_jpg_files):\n",
    "    # Upload the image to your project\n",
    "    project.upload(file)\n",
    "\n",
    "    print(\"uploaded {} of {}\".format(index + 1, len(cropped_jpg_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download dataset from roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from roboflow import Roboflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "rf = Roboflow(api_key=os.environ.get(\"ROBOFLOW_API_KEY\"))\n",
    "project = rf.workspace(\"long-zheng-bzpnl\").project(\"gate-open-or-closed\")\n",
    "dataset = project.version(5).download(\"folder\")\n",
    "\n",
    "# rename dataset /valid to /val\n",
    "import shutil\n",
    "shutil.move(dataset.location + \"/valid\", dataset.location + \"/val\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=classify mode=train model=yolov8n-cls.pt data='Gate-open-or-closed-5' epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload weights to roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from roboflow import Roboflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "rf = Roboflow(api_key=os.environ.get(\"ROBOFLOW_API_KEY\"))\n",
    "project = rf.workspace(\"long-zheng-bzpnl\").project(\"gate-open-or-closed\")\n",
    "version = project.version(5)\n",
    "version.deploy(\"yolov8-cls\", \"runs/classify/train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8n model\n",
    "model = YOLO('runs/classify/train/weights/best.pt')\n",
    "\n",
    "# OR define a recursive glob search for all JPG files including subdirectories\n",
    "source = 'Gate-open-or-closed-5/test/**/*.jpg'\n",
    "\n",
    "# Run inference on the source\n",
    "results = model(source, stream=True,)  # generator of Results objects\n",
    "\n",
    "for result in results:\n",
    "    print(result.probs.top1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export ONNX nodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo export model=runs/classify/train/weights/best.pt format=onnx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
